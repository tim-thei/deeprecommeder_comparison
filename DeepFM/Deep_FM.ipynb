{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Factorizaton Machine (Deep FM)\n",
    "\n",
    "#### Acknowledgement\n",
    "\n",
    "Guo, H., Tang, R., Ye, Y., Li, Z., and He, X. (2017). DeepFM: A\n",
    "Factorization-Machine based Neural Network for CTR Prediction. arXiv e-prints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import later used packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Rec_split import rec_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "from torch import nn\n",
    "from itertools import product\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, VarLenSparseFeat, get_feature_names\n",
    "from deepctr_torch.models import DeepFM\n",
    "\n",
    "# custom function see .py file\n",
    "from Kendall_distance import kendall_distance_with_penalty\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function used to save genre feature\n",
    "def split(x):\n",
    "    key_ans = x.split('|')\n",
    "    for key in key_ans:\n",
    "        if key not in key2index:\n",
    "            # Notice : input value 0 is a special \"padding\",so we do not use 0 to encode valid feature for sequence input\n",
    "            key2index[key] = len(key2index) + 1\n",
    "    return list(map(lambda x: key2index[x], key_ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "data = pd.read_csv(\"data/ml_1M_full.csv\")\n",
    "\n",
    "#split data\n",
    "train, val, test = rec_split(data, 'User', 'Timestamp', train_share=0.85, val_share=0.0)\n",
    "train['Rating'] = train['Rating'].apply(lambda x: 1 if x >= 4 else 0) #convert Rating to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dataset for prediction generation\n",
    "\n",
    "# create one dataframe with each movie and one with each user\n",
    "movie_columns = ['Movie', 'Genre', 'Release_Year']\n",
    "user_columns = ['User', 'Gender', 'Age', 'Occupation']\n",
    "\n",
    "movie_df = train[movie_columns].drop_duplicates()\n",
    "user_df = train[user_columns].drop_duplicates()\n",
    "\n",
    "# Create combinations of rows from both DataFrames\n",
    "combined_rows = [list(row1) + list(row2) for row1, row2 in product(movie_df.values, user_df.values)]\n",
    "\n",
    "# Create a new DataFrame with columns from both DataFrames and one row for each possible user-item interaction\n",
    "columns = list(movie_df.columns) + list(user_df.columns)\n",
    "prediction_df = pd.DataFrame(combined_rows, columns=columns)\n",
    "\n",
    "#remove data already in train\n",
    "merged_df = pd.merge(prediction_df, train, on=['User', 'Movie'], how='outer', indicator=True)\n",
    "prediction_df = merged_df[merged_df['_merge']=='left_only'].drop(columns=['_merge', 'Rating', 'Gender_y', 'Age_y', 'Occupation_y', 'Genre_y', 'Release_Year_y']).rename(columns=lambda x: x.replace('_x', ''))\n",
    "\n",
    "#remove movies exclusivly in test\n",
    "prediction_df = pd.merge(prediction_df, test, on=['User', 'Movie'], how='outer', indicator=True)\n",
    "test = prediction_df[prediction_df['_merge']!='right_only'].drop(columns=['_merge', 'Gender_y', 'Age_y', 'Occupation_y', 'Genre_y', 'Release_Year_y']).rename(columns=lambda x: x.replace('_x', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features used for training and predicting\n",
    "sparse_features = [\"User\", \"Movie\", \"Gender\", \"Age\", \"Occupation\"]\n",
    "target = ['Rating']\n",
    "\n",
    "# Label Encoding for sparse features,and process sequence features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    train[feat] = lbe.fit_transform(train[feat])\n",
    "    test[feat] = lbe.fit_transform(test[feat])\n",
    "\n",
    "# preprocess the Genre feature fror train data\n",
    "key2index = {} # save feature encoding\n",
    "genres_list = list(map(split, train['Genre'].values))\n",
    "genres_length = np.array(list(map(len, genres_list)))\n",
    "\n",
    "# preprocess the Genre feature for test data\n",
    "genres_list_test = list(map(split, test['Genre'].values))\n",
    "genres_length_test = np.array(list(map(len, genres_list_test)))\n",
    "\n",
    "max_len = max([max(genres_length), max(genres_length_test)])\n",
    "\n",
    "genres_list = pad_sequences(genres_list, maxlen=max_len, padding='post', )\n",
    "genres_list_test = pad_sequences(genres_list_test, maxlen=max_len, padding='post', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input features\n",
    "\n",
    "fixlen_feature_columns_sparce = [SparseFeat(feat, train[feat].nunique(), embedding_dim=4)\n",
    "                            for feat in sparse_features]\n",
    "\n",
    "varlen_feature_columns = [VarLenSparseFeat(SparseFeat('genres', vocabulary_size=len(\n",
    "    key2index) + 1, embedding_dim=4), maxlen=max_len, combiner='mean')]  # Notice : value 0 is for padding for sequence input feature\n",
    "\n",
    "linear_feature_columns = fixlen_feature_columns_sparce + varlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns_sparce + varlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate input data for training\n",
    "model_input = {name: train[name] for name in sparse_features}\n",
    "model_input[\"genres\"] = genres_list\n",
    "\n",
    "# generate input data for the predictions\n",
    "model_input_test = {name: test[name] for name in sparse_features}\n",
    "model_input_test[\"genres\"] = genres_list_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "hidden_layer = [[100, 100], [100, 100, 100], [400, 400], [400, 400, 400]]\n",
    "dropout_rate = 0.5\n",
    "activation = nn.ReLU\n",
    "\n",
    "learning_rate = [0.01, 0.001, 0.0001]\n",
    "epochs = [3, 5, 10]\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/3\n",
      "41s - loss:  0.5545 - binary_crossentropy:  0.5543 - auc:  0.7765 - val_binary_crossentropy:  0.6018 - val_auc:  0.7141\n",
      "Epoch 2/3\n",
      "40s - loss:  0.5203 - binary_crossentropy:  0.5197 - auc:  0.8096 - val_binary_crossentropy:  0.6038 - val_auc:  0.7115\n",
      "Epoch 3/3\n",
      "42s - loss:  0.5073 - binary_crossentropy:  0.5064 - auc:  0.8210 - val_binary_crossentropy:  0.6020 - val_auc:  0.7142\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/5\n",
      "45s - loss:  0.5545 - binary_crossentropy:  0.5543 - auc:  0.7765 - val_binary_crossentropy:  0.6018 - val_auc:  0.7141\n",
      "Epoch 2/5\n",
      "41s - loss:  0.5203 - binary_crossentropy:  0.5197 - auc:  0.8096 - val_binary_crossentropy:  0.6038 - val_auc:  0.7115\n",
      "Epoch 3/5\n",
      "42s - loss:  0.5073 - binary_crossentropy:  0.5064 - auc:  0.8210 - val_binary_crossentropy:  0.6020 - val_auc:  0.7142\n",
      "Epoch 4/5\n",
      "43s - loss:  0.5004 - binary_crossentropy:  0.4993 - auc:  0.8268 - val_binary_crossentropy:  0.6030 - val_auc:  0.7134\n",
      "Epoch 5/5\n",
      "41s - loss:  0.4969 - binary_crossentropy:  0.4954 - auc:  0.8299 - val_binary_crossentropy:  0.6091 - val_auc:  0.7099\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/10\n",
      "45s - loss:  0.5545 - binary_crossentropy:  0.5543 - auc:  0.7765 - val_binary_crossentropy:  0.6018 - val_auc:  0.7141\n",
      "Epoch 2/10\n",
      "43s - loss:  0.5203 - binary_crossentropy:  0.5197 - auc:  0.8096 - val_binary_crossentropy:  0.6038 - val_auc:  0.7115\n",
      "Epoch 3/10\n",
      "41s - loss:  0.5073 - binary_crossentropy:  0.5064 - auc:  0.8210 - val_binary_crossentropy:  0.6020 - val_auc:  0.7142\n",
      "Epoch 4/10\n",
      "43s - loss:  0.5004 - binary_crossentropy:  0.4993 - auc:  0.8268 - val_binary_crossentropy:  0.6030 - val_auc:  0.7134\n",
      "Epoch 5/10\n",
      "42s - loss:  0.4969 - binary_crossentropy:  0.4954 - auc:  0.8299 - val_binary_crossentropy:  0.6091 - val_auc:  0.7099\n",
      "Epoch 6/10\n",
      "44s - loss:  0.4949 - binary_crossentropy:  0.4931 - auc:  0.8317 - val_binary_crossentropy:  0.6039 - val_auc:  0.7138\n",
      "Epoch 7/10\n",
      "42s - loss:  0.4934 - binary_crossentropy:  0.4914 - auc:  0.8331 - val_binary_crossentropy:  0.6093 - val_auc:  0.7155\n",
      "Epoch 8/10\n",
      "40s - loss:  0.4925 - binary_crossentropy:  0.4903 - auc:  0.8340 - val_binary_crossentropy:  0.6096 - val_auc:  0.7105\n",
      "Epoch 9/10\n",
      "40s - loss:  0.4916 - binary_crossentropy:  0.4892 - auc:  0.8350 - val_binary_crossentropy:  0.6065 - val_auc:  0.7113\n",
      "Epoch 10/10\n",
      "41s - loss:  0.4911 - binary_crossentropy:  0.4885 - auc:  0.8355 - val_binary_crossentropy:  0.6114 - val_auc:  0.7105\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/3\n",
      "53s - loss:  0.5625 - binary_crossentropy:  0.5625 - auc:  0.7679 - val_binary_crossentropy:  0.5964 - val_auc:  0.7213\n",
      "Epoch 2/3\n",
      "39s - loss:  0.5388 - binary_crossentropy:  0.5388 - auc:  0.7919 - val_binary_crossentropy:  0.5962 - val_auc:  0.7216\n",
      "Epoch 3/3\n",
      "40s - loss:  0.5363 - binary_crossentropy:  0.5362 - auc:  0.7939 - val_binary_crossentropy:  0.5964 - val_auc:  0.7221\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/5\n",
      "42s - loss:  0.5625 - binary_crossentropy:  0.5625 - auc:  0.7679 - val_binary_crossentropy:  0.5964 - val_auc:  0.7213\n",
      "Epoch 2/5\n",
      "40s - loss:  0.5388 - binary_crossentropy:  0.5388 - auc:  0.7919 - val_binary_crossentropy:  0.5962 - val_auc:  0.7216\n",
      "Epoch 3/5\n",
      "40s - loss:  0.5363 - binary_crossentropy:  0.5362 - auc:  0.7939 - val_binary_crossentropy:  0.5964 - val_auc:  0.7221\n",
      "Epoch 4/5\n",
      "39s - loss:  0.5313 - binary_crossentropy:  0.5313 - auc:  0.7977 - val_binary_crossentropy:  0.5959 - val_auc:  0.7224\n",
      "Epoch 5/5\n",
      "40s - loss:  0.5249 - binary_crossentropy:  0.5249 - auc:  0.8030 - val_binary_crossentropy:  0.5947 - val_auc:  0.7230\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/10\n",
      "42s - loss:  0.5625 - binary_crossentropy:  0.5625 - auc:  0.7679 - val_binary_crossentropy:  0.5964 - val_auc:  0.7213\n",
      "Epoch 2/10\n",
      "40s - loss:  0.5388 - binary_crossentropy:  0.5388 - auc:  0.7919 - val_binary_crossentropy:  0.5962 - val_auc:  0.7216\n",
      "Epoch 3/10\n",
      "40s - loss:  0.5363 - binary_crossentropy:  0.5362 - auc:  0.7939 - val_binary_crossentropy:  0.5964 - val_auc:  0.7221\n",
      "Epoch 4/10\n",
      "40s - loss:  0.5313 - binary_crossentropy:  0.5313 - auc:  0.7977 - val_binary_crossentropy:  0.5959 - val_auc:  0.7224\n",
      "Epoch 5/10\n",
      "40s - loss:  0.5249 - binary_crossentropy:  0.5249 - auc:  0.8030 - val_binary_crossentropy:  0.5947 - val_auc:  0.7230\n",
      "Epoch 6/10\n",
      "40s - loss:  0.5203 - binary_crossentropy:  0.5202 - auc:  0.8071 - val_binary_crossentropy:  0.5953 - val_auc:  0.7223\n",
      "Epoch 7/10\n",
      "40s - loss:  0.5154 - binary_crossentropy:  0.5153 - auc:  0.8116 - val_binary_crossentropy:  0.5985 - val_auc:  0.7219\n",
      "Epoch 8/10\n",
      "40s - loss:  0.5103 - binary_crossentropy:  0.5103 - auc:  0.8163 - val_binary_crossentropy:  0.5979 - val_auc:  0.7202\n",
      "Epoch 9/10\n",
      "39s - loss:  0.5034 - binary_crossentropy:  0.5033 - auc:  0.8225 - val_binary_crossentropy:  0.6013 - val_auc:  0.7167\n",
      "Epoch 10/10\n",
      "39s - loss:  0.4968 - binary_crossentropy:  0.4967 - auc:  0.8280 - val_binary_crossentropy:  0.6012 - val_auc:  0.7175\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/3\n",
      "40s - loss:  0.6107 - binary_crossentropy:  0.6107 - auc:  0.7111 - val_binary_crossentropy:  0.5981 - val_auc:  0.7205\n",
      "Epoch 2/3\n",
      "40s - loss:  0.5397 - binary_crossentropy:  0.5397 - auc:  0.7932 - val_binary_crossentropy:  0.5964 - val_auc:  0.7224\n",
      "Epoch 3/3\n",
      "39s - loss:  0.5337 - binary_crossentropy:  0.5337 - auc:  0.7972 - val_binary_crossentropy:  0.5961 - val_auc:  0.7228\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/5\n",
      "41s - loss:  0.6107 - binary_crossentropy:  0.6107 - auc:  0.7111 - val_binary_crossentropy:  0.5981 - val_auc:  0.7205\n",
      "Epoch 2/5\n",
      "41s - loss:  0.5397 - binary_crossentropy:  0.5397 - auc:  0.7932 - val_binary_crossentropy:  0.5964 - val_auc:  0.7224\n",
      "Epoch 3/5\n",
      "38s - loss:  0.5337 - binary_crossentropy:  0.5337 - auc:  0.7972 - val_binary_crossentropy:  0.5961 - val_auc:  0.7228\n",
      "Epoch 4/5\n",
      "41s - loss:  0.5320 - binary_crossentropy:  0.5320 - auc:  0.7983 - val_binary_crossentropy:  0.5965 - val_auc:  0.7229\n",
      "Epoch 5/5\n",
      "41s - loss:  0.5313 - binary_crossentropy:  0.5313 - auc:  0.7987 - val_binary_crossentropy:  0.5956 - val_auc:  0.7230\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/10\n",
      "42s - loss:  0.6107 - binary_crossentropy:  0.6107 - auc:  0.7111 - val_binary_crossentropy:  0.5981 - val_auc:  0.7205\n",
      "Epoch 2/10\n",
      "41s - loss:  0.5397 - binary_crossentropy:  0.5397 - auc:  0.7932 - val_binary_crossentropy:  0.5964 - val_auc:  0.7224\n",
      "Epoch 3/10\n",
      "42s - loss:  0.5337 - binary_crossentropy:  0.5337 - auc:  0.7972 - val_binary_crossentropy:  0.5961 - val_auc:  0.7228\n",
      "Epoch 4/10\n",
      "46s - loss:  0.5320 - binary_crossentropy:  0.5320 - auc:  0.7983 - val_binary_crossentropy:  0.5965 - val_auc:  0.7229\n",
      "Epoch 5/10\n",
      "91s - loss:  0.5313 - binary_crossentropy:  0.5313 - auc:  0.7987 - val_binary_crossentropy:  0.5956 - val_auc:  0.7230\n",
      "Epoch 6/10\n",
      "98s - loss:  0.5309 - binary_crossentropy:  0.5309 - auc:  0.7989 - val_binary_crossentropy:  0.5960 - val_auc:  0.7229\n",
      "Epoch 7/10\n",
      "96s - loss:  0.5305 - binary_crossentropy:  0.5305 - auc:  0.7991 - val_binary_crossentropy:  0.5963 - val_auc:  0.7230\n",
      "Epoch 8/10\n",
      "98s - loss:  0.5304 - binary_crossentropy:  0.5304 - auc:  0.7991 - val_binary_crossentropy:  0.5967 - val_auc:  0.7229\n",
      "Epoch 9/10\n",
      "92s - loss:  0.5302 - binary_crossentropy:  0.5302 - auc:  0.7994 - val_binary_crossentropy:  0.5963 - val_auc:  0.7231\n",
      "Epoch 10/10\n",
      "91s - loss:  0.5300 - binary_crossentropy:  0.5300 - auc:  0.7994 - val_binary_crossentropy:  0.5963 - val_auc:  0.7229\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/3\n",
      "108s - loss:  0.5557 - binary_crossentropy:  0.5556 - auc:  0.7754 - val_binary_crossentropy:  0.5983 - val_auc:  0.7192\n",
      "Epoch 2/3\n",
      "96s - loss:  0.5211 - binary_crossentropy:  0.5205 - auc:  0.8089 - val_binary_crossentropy:  0.5996 - val_auc:  0.7199\n",
      "Epoch 3/3\n",
      "45s - loss:  0.5069 - binary_crossentropy:  0.5060 - auc:  0.8213 - val_binary_crossentropy:  0.6008 - val_auc:  0.7164\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/5\n",
      "46s - loss:  0.5557 - binary_crossentropy:  0.5556 - auc:  0.7754 - val_binary_crossentropy:  0.5983 - val_auc:  0.7192\n",
      "Epoch 2/5\n",
      "46s - loss:  0.5211 - binary_crossentropy:  0.5205 - auc:  0.8089 - val_binary_crossentropy:  0.5996 - val_auc:  0.7199\n",
      "Epoch 3/5\n",
      "47s - loss:  0.5069 - binary_crossentropy:  0.5060 - auc:  0.8213 - val_binary_crossentropy:  0.6008 - val_auc:  0.7164\n",
      "Epoch 4/5\n",
      "44s - loss:  0.5002 - binary_crossentropy:  0.4990 - auc:  0.8269 - val_binary_crossentropy:  0.6020 - val_auc:  0.7152\n",
      "Epoch 5/5\n",
      "45s - loss:  0.4971 - binary_crossentropy:  0.4956 - auc:  0.8297 - val_binary_crossentropy:  0.6084 - val_auc:  0.7149\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/10\n",
      "47s - loss:  0.5557 - binary_crossentropy:  0.5556 - auc:  0.7754 - val_binary_crossentropy:  0.5983 - val_auc:  0.7192\n",
      "Epoch 2/10\n",
      "45s - loss:  0.5211 - binary_crossentropy:  0.5205 - auc:  0.8089 - val_binary_crossentropy:  0.5996 - val_auc:  0.7199\n",
      "Epoch 3/10\n",
      "46s - loss:  0.5069 - binary_crossentropy:  0.5060 - auc:  0.8213 - val_binary_crossentropy:  0.6008 - val_auc:  0.7164\n",
      "Epoch 4/10\n",
      "45s - loss:  0.5002 - binary_crossentropy:  0.4990 - auc:  0.8269 - val_binary_crossentropy:  0.6020 - val_auc:  0.7152\n",
      "Epoch 5/10\n",
      "47s - loss:  0.4971 - binary_crossentropy:  0.4956 - auc:  0.8297 - val_binary_crossentropy:  0.6084 - val_auc:  0.7149\n",
      "Epoch 6/10\n",
      "45s - loss:  0.4954 - binary_crossentropy:  0.4936 - auc:  0.8314 - val_binary_crossentropy:  0.6061 - val_auc:  0.7130\n",
      "Epoch 7/10\n",
      "45s - loss:  0.4940 - binary_crossentropy:  0.4920 - auc:  0.8326 - val_binary_crossentropy:  0.6069 - val_auc:  0.7164\n",
      "Epoch 8/10\n",
      "45s - loss:  0.4934 - binary_crossentropy:  0.4912 - auc:  0.8333 - val_binary_crossentropy:  0.6064 - val_auc:  0.7126\n",
      "Epoch 9/10\n",
      "44s - loss:  0.4927 - binary_crossentropy:  0.4903 - auc:  0.8340 - val_binary_crossentropy:  0.6113 - val_auc:  0.7067\n",
      "Epoch 10/10\n",
      "47s - loss:  0.4914 - binary_crossentropy:  0.4888 - auc:  0.8351 - val_binary_crossentropy:  0.6078 - val_auc:  0.7139\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/3\n",
      "48s - loss:  0.5632 - binary_crossentropy:  0.5631 - auc:  0.7668 - val_binary_crossentropy:  0.5977 - val_auc:  0.7206\n",
      "Epoch 2/3\n",
      "46s - loss:  0.5389 - binary_crossentropy:  0.5389 - auc:  0.7917 - val_binary_crossentropy:  0.5962 - val_auc:  0.7216\n",
      "Epoch 3/3\n",
      "50s - loss:  0.5364 - binary_crossentropy:  0.5363 - auc:  0.7938 - val_binary_crossentropy:  0.5960 - val_auc:  0.7224\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/5\n",
      "46s - loss:  0.5632 - binary_crossentropy:  0.5631 - auc:  0.7668 - val_binary_crossentropy:  0.5977 - val_auc:  0.7206\n",
      "Epoch 2/5\n",
      "43s - loss:  0.5389 - binary_crossentropy:  0.5389 - auc:  0.7917 - val_binary_crossentropy:  0.5962 - val_auc:  0.7216\n",
      "Epoch 3/5\n",
      "47s - loss:  0.5364 - binary_crossentropy:  0.5363 - auc:  0.7938 - val_binary_crossentropy:  0.5960 - val_auc:  0.7224\n",
      "Epoch 4/5\n",
      "43s - loss:  0.5317 - binary_crossentropy:  0.5317 - auc:  0.7975 - val_binary_crossentropy:  0.5962 - val_auc:  0.7220\n",
      "Epoch 5/5\n",
      "46s - loss:  0.5255 - binary_crossentropy:  0.5255 - auc:  0.8026 - val_binary_crossentropy:  0.5983 - val_auc:  0.7227\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/10\n",
      "55s - loss:  0.5632 - binary_crossentropy:  0.5631 - auc:  0.7668 - val_binary_crossentropy:  0.5977 - val_auc:  0.7206\n",
      "Epoch 2/10\n",
      "49s - loss:  0.5389 - binary_crossentropy:  0.5389 - auc:  0.7917 - val_binary_crossentropy:  0.5962 - val_auc:  0.7216\n",
      "Epoch 3/10\n",
      "48s - loss:  0.5364 - binary_crossentropy:  0.5363 - auc:  0.7938 - val_binary_crossentropy:  0.5960 - val_auc:  0.7224\n",
      "Epoch 4/10\n",
      "46s - loss:  0.5317 - binary_crossentropy:  0.5317 - auc:  0.7975 - val_binary_crossentropy:  0.5962 - val_auc:  0.7220\n",
      "Epoch 5/10\n",
      "41s - loss:  0.5255 - binary_crossentropy:  0.5255 - auc:  0.8026 - val_binary_crossentropy:  0.5983 - val_auc:  0.7227\n",
      "Epoch 6/10\n",
      "45s - loss:  0.5215 - binary_crossentropy:  0.5214 - auc:  0.8060 - val_binary_crossentropy:  0.5955 - val_auc:  0.7225\n",
      "Epoch 7/10\n",
      "45s - loss:  0.5178 - binary_crossentropy:  0.5178 - auc:  0.8093 - val_binary_crossentropy:  0.5955 - val_auc:  0.7237\n",
      "Epoch 8/10\n",
      "41s - loss:  0.5136 - binary_crossentropy:  0.5135 - auc:  0.8133 - val_binary_crossentropy:  0.5987 - val_auc:  0.7209\n",
      "Epoch 9/10\n",
      "45s - loss:  0.5090 - binary_crossentropy:  0.5089 - auc:  0.8176 - val_binary_crossentropy:  0.6039 - val_auc:  0.7134\n",
      "Epoch 10/10\n",
      "48s - loss:  0.5035 - binary_crossentropy:  0.5034 - auc:  0.8225 - val_binary_crossentropy:  0.6017 - val_auc:  0.7170\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/3\n",
      "45s - loss:  0.6086 - binary_crossentropy:  0.6086 - auc:  0.7107 - val_binary_crossentropy:  0.5987 - val_auc:  0.7204\n",
      "Epoch 2/3\n",
      "47s - loss:  0.5394 - binary_crossentropy:  0.5394 - auc:  0.7936 - val_binary_crossentropy:  0.5969 - val_auc:  0.7225\n",
      "Epoch 3/3\n",
      "41s - loss:  0.5338 - binary_crossentropy:  0.5338 - auc:  0.7972 - val_binary_crossentropy:  0.5959 - val_auc:  0.7229\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/5\n",
      "46s - loss:  0.6086 - binary_crossentropy:  0.6086 - auc:  0.7107 - val_binary_crossentropy:  0.5987 - val_auc:  0.7204\n",
      "Epoch 2/5\n",
      "45s - loss:  0.5394 - binary_crossentropy:  0.5394 - auc:  0.7936 - val_binary_crossentropy:  0.5969 - val_auc:  0.7225\n",
      "Epoch 3/5\n",
      "40s - loss:  0.5338 - binary_crossentropy:  0.5338 - auc:  0.7972 - val_binary_crossentropy:  0.5959 - val_auc:  0.7229\n",
      "Epoch 4/5\n",
      "46s - loss:  0.5322 - binary_crossentropy:  0.5321 - auc:  0.7982 - val_binary_crossentropy:  0.5973 - val_auc:  0.7230\n",
      "Epoch 5/5\n",
      "51s - loss:  0.5314 - binary_crossentropy:  0.5314 - auc:  0.7986 - val_binary_crossentropy:  0.5981 - val_auc:  0.7231\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/10\n",
      "50s - loss:  0.6086 - binary_crossentropy:  0.6086 - auc:  0.7107 - val_binary_crossentropy:  0.5987 - val_auc:  0.7204\n",
      "Epoch 2/10\n",
      "48s - loss:  0.5394 - binary_crossentropy:  0.5394 - auc:  0.7936 - val_binary_crossentropy:  0.5969 - val_auc:  0.7225\n",
      "Epoch 3/10\n",
      "44s - loss:  0.5338 - binary_crossentropy:  0.5338 - auc:  0.7972 - val_binary_crossentropy:  0.5959 - val_auc:  0.7229\n",
      "Epoch 4/10\n",
      "48s - loss:  0.5322 - binary_crossentropy:  0.5321 - auc:  0.7982 - val_binary_crossentropy:  0.5973 - val_auc:  0.7230\n",
      "Epoch 5/10\n",
      "52s - loss:  0.5314 - binary_crossentropy:  0.5314 - auc:  0.7986 - val_binary_crossentropy:  0.5981 - val_auc:  0.7231\n",
      "Epoch 6/10\n",
      "52s - loss:  0.5311 - binary_crossentropy:  0.5311 - auc:  0.7987 - val_binary_crossentropy:  0.5962 - val_auc:  0.7232\n",
      "Epoch 7/10\n",
      "53s - loss:  0.5307 - binary_crossentropy:  0.5307 - auc:  0.7990 - val_binary_crossentropy:  0.5970 - val_auc:  0.7233\n",
      "Epoch 8/10\n",
      "53s - loss:  0.5305 - binary_crossentropy:  0.5305 - auc:  0.7991 - val_binary_crossentropy:  0.5970 - val_auc:  0.7233\n",
      "Epoch 9/10\n",
      "54s - loss:  0.5303 - binary_crossentropy:  0.5303 - auc:  0.7993 - val_binary_crossentropy:  0.5965 - val_auc:  0.7233\n",
      "Epoch 10/10\n",
      "51s - loss:  0.5301 - binary_crossentropy:  0.5301 - auc:  0.7995 - val_binary_crossentropy:  0.5969 - val_auc:  0.7234\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/3\n",
      "71s - loss:  0.5554 - binary_crossentropy:  0.5552 - auc:  0.7757 - val_binary_crossentropy:  0.5994 - val_auc:  0.7181\n",
      "Epoch 2/3\n",
      "71s - loss:  0.5212 - binary_crossentropy:  0.5207 - auc:  0.8088 - val_binary_crossentropy:  0.5988 - val_auc:  0.7208\n",
      "Epoch 3/3\n",
      "73s - loss:  0.5072 - binary_crossentropy:  0.5064 - auc:  0.8211 - val_binary_crossentropy:  0.6004 - val_auc:  0.7176\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/5\n",
      "70s - loss:  0.5554 - binary_crossentropy:  0.5552 - auc:  0.7757 - val_binary_crossentropy:  0.5994 - val_auc:  0.7181\n",
      "Epoch 2/5\n",
      "72s - loss:  0.5212 - binary_crossentropy:  0.5207 - auc:  0.8088 - val_binary_crossentropy:  0.5988 - val_auc:  0.7208\n",
      "Epoch 3/5\n",
      "72s - loss:  0.5072 - binary_crossentropy:  0.5064 - auc:  0.8211 - val_binary_crossentropy:  0.6004 - val_auc:  0.7176\n",
      "Epoch 4/5\n",
      "73s - loss:  0.5007 - binary_crossentropy:  0.4995 - auc:  0.8267 - val_binary_crossentropy:  0.6029 - val_auc:  0.7163\n",
      "Epoch 5/5\n",
      "73s - loss:  0.4973 - binary_crossentropy:  0.4958 - auc:  0.8297 - val_binary_crossentropy:  0.6029 - val_auc:  0.7180\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/10\n",
      "71s - loss:  0.5554 - binary_crossentropy:  0.5552 - auc:  0.7757 - val_binary_crossentropy:  0.5994 - val_auc:  0.7181\n",
      "Epoch 2/10\n",
      "71s - loss:  0.5212 - binary_crossentropy:  0.5207 - auc:  0.8088 - val_binary_crossentropy:  0.5988 - val_auc:  0.7208\n",
      "Epoch 3/10\n",
      "72s - loss:  0.5072 - binary_crossentropy:  0.5064 - auc:  0.8211 - val_binary_crossentropy:  0.6004 - val_auc:  0.7176\n",
      "Epoch 4/10\n",
      "72s - loss:  0.5007 - binary_crossentropy:  0.4995 - auc:  0.8267 - val_binary_crossentropy:  0.6029 - val_auc:  0.7163\n",
      "Epoch 5/10\n",
      "73s - loss:  0.4973 - binary_crossentropy:  0.4958 - auc:  0.8297 - val_binary_crossentropy:  0.6029 - val_auc:  0.7180\n",
      "Epoch 6/10\n",
      "74s - loss:  0.4948 - binary_crossentropy:  0.4930 - auc:  0.8318 - val_binary_crossentropy:  0.6095 - val_auc:  0.7144\n",
      "Epoch 7/10\n",
      "74s - loss:  0.4937 - binary_crossentropy:  0.4917 - auc:  0.8331 - val_binary_crossentropy:  0.6063 - val_auc:  0.7143\n",
      "Epoch 8/10\n",
      "76s - loss:  0.4926 - binary_crossentropy:  0.4904 - auc:  0.8340 - val_binary_crossentropy:  0.6121 - val_auc:  0.7142\n",
      "Epoch 9/10\n",
      "78s - loss:  0.4921 - binary_crossentropy:  0.4897 - auc:  0.8348 - val_binary_crossentropy:  0.6118 - val_auc:  0.7118\n",
      "Epoch 10/10\n",
      "77s - loss:  0.4914 - binary_crossentropy:  0.4888 - auc:  0.8354 - val_binary_crossentropy:  0.6078 - val_auc:  0.7146\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/3\n",
      "73s - loss:  0.5596 - binary_crossentropy:  0.5596 - auc:  0.7706 - val_binary_crossentropy:  0.5985 - val_auc:  0.7199\n",
      "Epoch 2/3\n",
      "66s - loss:  0.5392 - binary_crossentropy:  0.5392 - auc:  0.7912 - val_binary_crossentropy:  0.5978 - val_auc:  0.7211\n",
      "Epoch 3/3\n",
      "66s - loss:  0.5332 - binary_crossentropy:  0.5332 - auc:  0.7963 - val_binary_crossentropy:  0.5954 - val_auc:  0.7216\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/5\n",
      "68s - loss:  0.5596 - binary_crossentropy:  0.5596 - auc:  0.7706 - val_binary_crossentropy:  0.5985 - val_auc:  0.7199\n",
      "Epoch 2/5\n",
      "66s - loss:  0.5392 - binary_crossentropy:  0.5392 - auc:  0.7912 - val_binary_crossentropy:  0.5978 - val_auc:  0.7211\n",
      "Epoch 3/5\n",
      "67s - loss:  0.5332 - binary_crossentropy:  0.5332 - auc:  0.7963 - val_binary_crossentropy:  0.5954 - val_auc:  0.7216\n",
      "Epoch 4/5\n",
      "67s - loss:  0.5249 - binary_crossentropy:  0.5249 - auc:  0.8033 - val_binary_crossentropy:  0.5950 - val_auc:  0.7227\n",
      "Epoch 5/5\n",
      "67s - loss:  0.5193 - binary_crossentropy:  0.5192 - auc:  0.8081 - val_binary_crossentropy:  0.5947 - val_auc:  0.7234\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/10\n",
      "67s - loss:  0.5596 - binary_crossentropy:  0.5596 - auc:  0.7706 - val_binary_crossentropy:  0.5985 - val_auc:  0.7199\n",
      "Epoch 2/10\n",
      "69s - loss:  0.5392 - binary_crossentropy:  0.5392 - auc:  0.7912 - val_binary_crossentropy:  0.5978 - val_auc:  0.7211\n",
      "Epoch 3/10\n",
      "66s - loss:  0.5332 - binary_crossentropy:  0.5332 - auc:  0.7963 - val_binary_crossentropy:  0.5954 - val_auc:  0.7216\n",
      "Epoch 4/10\n",
      "67s - loss:  0.5249 - binary_crossentropy:  0.5249 - auc:  0.8033 - val_binary_crossentropy:  0.5950 - val_auc:  0.7227\n",
      "Epoch 5/10\n",
      "66s - loss:  0.5193 - binary_crossentropy:  0.5192 - auc:  0.8081 - val_binary_crossentropy:  0.5947 - val_auc:  0.7234\n",
      "Epoch 6/10\n",
      "67s - loss:  0.5123 - binary_crossentropy:  0.5122 - auc:  0.8147 - val_binary_crossentropy:  0.5990 - val_auc:  0.7232\n",
      "Epoch 7/10\n",
      "66s - loss:  0.5028 - binary_crossentropy:  0.5027 - auc:  0.8230 - val_binary_crossentropy:  0.5992 - val_auc:  0.7203\n",
      "Epoch 8/10\n",
      "68s - loss:  0.4939 - binary_crossentropy:  0.4938 - auc:  0.8302 - val_binary_crossentropy:  0.6020 - val_auc:  0.7199\n",
      "Epoch 9/10\n",
      "68s - loss:  0.4885 - binary_crossentropy:  0.4884 - auc:  0.8346 - val_binary_crossentropy:  0.6009 - val_auc:  0.7175\n",
      "Epoch 10/10\n",
      "68s - loss:  0.4851 - binary_crossentropy:  0.4850 - auc:  0.8370 - val_binary_crossentropy:  0.6004 - val_auc:  0.7186\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/3\n",
      "66s - loss:  0.5892 - binary_crossentropy:  0.5891 - auc:  0.7338 - val_binary_crossentropy:  0.5967 - val_auc:  0.7215\n",
      "Epoch 2/3\n",
      "65s - loss:  0.5368 - binary_crossentropy:  0.5368 - auc:  0.7946 - val_binary_crossentropy:  0.5959 - val_auc:  0.7227\n",
      "Epoch 3/3\n",
      "66s - loss:  0.5335 - binary_crossentropy:  0.5335 - auc:  0.7969 - val_binary_crossentropy:  0.5962 - val_auc:  0.7229\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/5\n",
      "67s - loss:  0.5892 - binary_crossentropy:  0.5891 - auc:  0.7338 - val_binary_crossentropy:  0.5967 - val_auc:  0.7215\n",
      "Epoch 2/5\n",
      "64s - loss:  0.5368 - binary_crossentropy:  0.5368 - auc:  0.7946 - val_binary_crossentropy:  0.5959 - val_auc:  0.7227\n",
      "Epoch 3/5\n",
      "64s - loss:  0.5335 - binary_crossentropy:  0.5335 - auc:  0.7969 - val_binary_crossentropy:  0.5962 - val_auc:  0.7229\n",
      "Epoch 4/5\n",
      "64s - loss:  0.5324 - binary_crossentropy:  0.5324 - auc:  0.7976 - val_binary_crossentropy:  0.5969 - val_auc:  0.7227\n",
      "Epoch 5/5\n",
      "65s - loss:  0.5319 - binary_crossentropy:  0.5319 - auc:  0.7980 - val_binary_crossentropy:  0.5957 - val_auc:  0.7233\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/10\n",
      "67s - loss:  0.5892 - binary_crossentropy:  0.5891 - auc:  0.7338 - val_binary_crossentropy:  0.5967 - val_auc:  0.7215\n",
      "Epoch 2/10\n",
      "65s - loss:  0.5368 - binary_crossentropy:  0.5368 - auc:  0.7946 - val_binary_crossentropy:  0.5959 - val_auc:  0.7227\n",
      "Epoch 3/10\n",
      "65s - loss:  0.5335 - binary_crossentropy:  0.5335 - auc:  0.7969 - val_binary_crossentropy:  0.5962 - val_auc:  0.7229\n",
      "Epoch 4/10\n",
      "65s - loss:  0.5324 - binary_crossentropy:  0.5324 - auc:  0.7976 - val_binary_crossentropy:  0.5969 - val_auc:  0.7227\n",
      "Epoch 5/10\n",
      "65s - loss:  0.5319 - binary_crossentropy:  0.5319 - auc:  0.7980 - val_binary_crossentropy:  0.5957 - val_auc:  0.7233\n",
      "Epoch 6/10\n",
      "66s - loss:  0.5315 - binary_crossentropy:  0.5315 - auc:  0.7982 - val_binary_crossentropy:  0.5971 - val_auc:  0.7231\n",
      "Epoch 7/10\n",
      "66s - loss:  0.5312 - binary_crossentropy:  0.5312 - auc:  0.7985 - val_binary_crossentropy:  0.5960 - val_auc:  0.7231\n",
      "Epoch 8/10\n",
      "65s - loss:  0.5309 - binary_crossentropy:  0.5309 - auc:  0.7986 - val_binary_crossentropy:  0.5965 - val_auc:  0.7231\n",
      "Epoch 9/10\n",
      "65s - loss:  0.5307 - binary_crossentropy:  0.5307 - auc:  0.7989 - val_binary_crossentropy:  0.5960 - val_auc:  0.7232\n",
      "Epoch 10/10\n",
      "66s - loss:  0.5305 - binary_crossentropy:  0.5305 - auc:  0.7990 - val_binary_crossentropy:  0.5957 - val_auc:  0.7230\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/3\n",
      "92s - loss:  0.5577 - binary_crossentropy:  0.5575 - auc:  0.7740 - val_binary_crossentropy:  0.5976 - val_auc:  0.7187\n",
      "Epoch 2/3\n",
      "93s - loss:  0.5267 - binary_crossentropy:  0.5262 - auc:  0.8038 - val_binary_crossentropy:  0.5990 - val_auc:  0.7186\n",
      "Epoch 3/3\n",
      "95s - loss:  0.5125 - binary_crossentropy:  0.5117 - auc:  0.8167 - val_binary_crossentropy:  0.6004 - val_auc:  0.7188\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/5\n",
      "92s - loss:  0.5577 - binary_crossentropy:  0.5575 - auc:  0.7740 - val_binary_crossentropy:  0.5976 - val_auc:  0.7187\n",
      "Epoch 2/5\n",
      "93s - loss:  0.5267 - binary_crossentropy:  0.5262 - auc:  0.8038 - val_binary_crossentropy:  0.5990 - val_auc:  0.7186\n",
      "Epoch 3/5\n",
      "93s - loss:  0.5125 - binary_crossentropy:  0.5117 - auc:  0.8167 - val_binary_crossentropy:  0.6004 - val_auc:  0.7188\n",
      "Epoch 4/5\n",
      "93s - loss:  0.5057 - binary_crossentropy:  0.5046 - auc:  0.8227 - val_binary_crossentropy:  0.6056 - val_auc:  0.7141\n",
      "Epoch 5/5\n",
      "94s - loss:  0.5026 - binary_crossentropy:  0.5013 - auc:  0.8256 - val_binary_crossentropy:  0.6084 - val_auc:  0.7145\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/10\n",
      "93s - loss:  0.5577 - binary_crossentropy:  0.5575 - auc:  0.7740 - val_binary_crossentropy:  0.5976 - val_auc:  0.7187\n",
      "Epoch 2/10\n",
      "93s - loss:  0.5267 - binary_crossentropy:  0.5262 - auc:  0.8038 - val_binary_crossentropy:  0.5990 - val_auc:  0.7186\n",
      "Epoch 3/10\n",
      "94s - loss:  0.5125 - binary_crossentropy:  0.5117 - auc:  0.8167 - val_binary_crossentropy:  0.6004 - val_auc:  0.7188\n",
      "Epoch 4/10\n",
      "92s - loss:  0.5057 - binary_crossentropy:  0.5046 - auc:  0.8227 - val_binary_crossentropy:  0.6056 - val_auc:  0.7141\n",
      "Epoch 5/10\n",
      "94s - loss:  0.5026 - binary_crossentropy:  0.5013 - auc:  0.8256 - val_binary_crossentropy:  0.6084 - val_auc:  0.7145\n",
      "Epoch 6/10\n",
      "91s - loss:  0.5008 - binary_crossentropy:  0.4993 - auc:  0.8273 - val_binary_crossentropy:  0.6114 - val_auc:  0.7087\n",
      "Epoch 7/10\n",
      "92s - loss:  0.4996 - binary_crossentropy:  0.4980 - auc:  0.8284 - val_binary_crossentropy:  0.6113 - val_auc:  0.7106\n",
      "Epoch 8/10\n",
      "93s - loss:  0.4987 - binary_crossentropy:  0.4970 - auc:  0.8294 - val_binary_crossentropy:  0.6102 - val_auc:  0.7079\n",
      "Epoch 9/10\n",
      "95s - loss:  0.4980 - binary_crossentropy:  0.4962 - auc:  0.8299 - val_binary_crossentropy:  0.6120 - val_auc:  0.7123\n",
      "Epoch 10/10\n",
      "96s - loss:  0.4976 - binary_crossentropy:  0.4957 - auc:  0.8303 - val_binary_crossentropy:  0.6149 - val_auc:  0.7095\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/3\n",
      "86s - loss:  0.5609 - binary_crossentropy:  0.5609 - auc:  0.7695 - val_binary_crossentropy:  0.5988 - val_auc:  0.7196\n",
      "Epoch 2/3\n",
      "88s - loss:  0.5394 - binary_crossentropy:  0.5394 - auc:  0.7912 - val_binary_crossentropy:  0.6008 - val_auc:  0.7215\n",
      "Epoch 3/3\n",
      "87s - loss:  0.5337 - binary_crossentropy:  0.5337 - auc:  0.7959 - val_binary_crossentropy:  0.5964 - val_auc:  0.7222\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/5\n",
      "87s - loss:  0.5609 - binary_crossentropy:  0.5609 - auc:  0.7695 - val_binary_crossentropy:  0.5988 - val_auc:  0.7196\n",
      "Epoch 2/5\n",
      "87s - loss:  0.5394 - binary_crossentropy:  0.5394 - auc:  0.7912 - val_binary_crossentropy:  0.6008 - val_auc:  0.7215\n",
      "Epoch 3/5\n",
      "85s - loss:  0.5337 - binary_crossentropy:  0.5337 - auc:  0.7959 - val_binary_crossentropy:  0.5964 - val_auc:  0.7222\n",
      "Epoch 4/5\n",
      "78s - loss:  0.5260 - binary_crossentropy:  0.5259 - auc:  0.8022 - val_binary_crossentropy:  0.5967 - val_auc:  0.7219\n",
      "Epoch 5/5\n",
      "84s - loss:  0.5217 - binary_crossentropy:  0.5217 - auc:  0.8060 - val_binary_crossentropy:  0.5955 - val_auc:  0.7225\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/10\n",
      "76s - loss:  0.5609 - binary_crossentropy:  0.5609 - auc:  0.7695 - val_binary_crossentropy:  0.5988 - val_auc:  0.7196\n",
      "Epoch 2/10\n",
      "87s - loss:  0.5394 - binary_crossentropy:  0.5394 - auc:  0.7912 - val_binary_crossentropy:  0.6008 - val_auc:  0.7215\n",
      "Epoch 3/10\n",
      "76s - loss:  0.5337 - binary_crossentropy:  0.5337 - auc:  0.7959 - val_binary_crossentropy:  0.5964 - val_auc:  0.7222\n",
      "Epoch 4/10\n",
      "87s - loss:  0.5260 - binary_crossentropy:  0.5259 - auc:  0.8022 - val_binary_crossentropy:  0.5967 - val_auc:  0.7219\n",
      "Epoch 5/10\n",
      "76s - loss:  0.5217 - binary_crossentropy:  0.5217 - auc:  0.8060 - val_binary_crossentropy:  0.5955 - val_auc:  0.7225\n",
      "Epoch 6/10\n",
      "87s - loss:  0.5183 - binary_crossentropy:  0.5183 - auc:  0.8090 - val_binary_crossentropy:  0.5951 - val_auc:  0.7233\n",
      "Epoch 7/10\n",
      "79s - loss:  0.5141 - binary_crossentropy:  0.5141 - auc:  0.8128 - val_binary_crossentropy:  0.5951 - val_auc:  0.7238\n",
      "Epoch 8/10\n",
      "85s - loss:  0.5087 - binary_crossentropy:  0.5087 - auc:  0.8176 - val_binary_crossentropy:  0.5963 - val_auc:  0.7215\n",
      "Epoch 9/10\n",
      "83s - loss:  0.5027 - binary_crossentropy:  0.5026 - auc:  0.8228 - val_binary_crossentropy:  0.5974 - val_auc:  0.7220\n",
      "Epoch 10/10\n",
      "86s - loss:  0.4970 - binary_crossentropy:  0.4970 - auc:  0.8274 - val_binary_crossentropy:  0.6018 - val_auc:  0.7209\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/3\n",
      "71s - loss:  0.5886 - binary_crossentropy:  0.5886 - auc:  0.7323 - val_binary_crossentropy:  0.5970 - val_auc:  0.7216\n",
      "Epoch 2/3\n",
      "69s - loss:  0.5367 - binary_crossentropy:  0.5367 - auc:  0.7946 - val_binary_crossentropy:  0.5979 - val_auc:  0.7227\n",
      "Epoch 3/3\n",
      "67s - loss:  0.5338 - binary_crossentropy:  0.5338 - auc:  0.7967 - val_binary_crossentropy:  0.5973 - val_auc:  0.7230\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/5\n",
      "74s - loss:  0.5886 - binary_crossentropy:  0.5886 - auc:  0.7323 - val_binary_crossentropy:  0.5970 - val_auc:  0.7216\n",
      "Epoch 2/5\n",
      "66s - loss:  0.5367 - binary_crossentropy:  0.5367 - auc:  0.7946 - val_binary_crossentropy:  0.5979 - val_auc:  0.7227\n",
      "Epoch 3/5\n",
      "72s - loss:  0.5338 - binary_crossentropy:  0.5338 - auc:  0.7967 - val_binary_crossentropy:  0.5973 - val_auc:  0.7230\n",
      "Epoch 4/5\n",
      "66s - loss:  0.5328 - binary_crossentropy:  0.5328 - auc:  0.7972 - val_binary_crossentropy:  0.5968 - val_auc:  0.7229\n",
      "Epoch 5/5\n",
      "72s - loss:  0.5323 - binary_crossentropy:  0.5323 - auc:  0.7979 - val_binary_crossentropy:  0.5966 - val_auc:  0.7230\n",
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/10\n",
      "69s - loss:  0.5886 - binary_crossentropy:  0.5886 - auc:  0.7323 - val_binary_crossentropy:  0.5970 - val_auc:  0.7216\n",
      "Epoch 2/10\n",
      "71s - loss:  0.5367 - binary_crossentropy:  0.5367 - auc:  0.7946 - val_binary_crossentropy:  0.5979 - val_auc:  0.7227\n",
      "Epoch 3/10\n",
      "64s - loss:  0.5338 - binary_crossentropy:  0.5338 - auc:  0.7967 - val_binary_crossentropy:  0.5973 - val_auc:  0.7230\n",
      "Epoch 4/10\n",
      "73s - loss:  0.5328 - binary_crossentropy:  0.5328 - auc:  0.7972 - val_binary_crossentropy:  0.5968 - val_auc:  0.7229\n",
      "Epoch 5/10\n",
      "64s - loss:  0.5323 - binary_crossentropy:  0.5323 - auc:  0.7979 - val_binary_crossentropy:  0.5966 - val_auc:  0.7230\n",
      "Epoch 6/10\n",
      "72s - loss:  0.5318 - binary_crossentropy:  0.5318 - auc:  0.7981 - val_binary_crossentropy:  0.5955 - val_auc:  0.7232\n",
      "Epoch 7/10\n",
      "65s - loss:  0.5314 - binary_crossentropy:  0.5314 - auc:  0.7983 - val_binary_crossentropy:  0.5963 - val_auc:  0.7233\n",
      "Epoch 8/10\n",
      "70s - loss:  0.5311 - binary_crossentropy:  0.5311 - auc:  0.7986 - val_binary_crossentropy:  0.5962 - val_auc:  0.7233\n",
      "Epoch 9/10\n",
      "67s - loss:  0.5309 - binary_crossentropy:  0.5309 - auc:  0.7988 - val_binary_crossentropy:  0.5968 - val_auc:  0.7233\n",
      "Epoch 10/10\n",
      "71s - loss:  0.5307 - binary_crossentropy:  0.5307 - auc:  0.7990 - val_binary_crossentropy:  0.5971 - val_auc:  0.7233\n"
     ]
    }
   ],
   "source": [
    "# generate empty dataframe to save results\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for layers in hidden_layer:\n",
    "    for lr in learning_rate:\n",
    "        for epoch in epochs:\n",
    "            # train the model for each hyperparameter combination\n",
    "            model = DeepFM(linear_feature_columns, dnn_feature_columns, use_fm=True, \n",
    "                        dnn_hidden_units=layers,\n",
    "                        dnn_dropout=dropout_rate,\n",
    "                        task='binary',\n",
    "                        dnn_activation=activation)\n",
    "\n",
    "            model.compile(torch.optim.Adam(model.parameters(), lr=lr), 'binary_crossentropy', metrics=['binary_crossentropy', 'auc'])\n",
    "            history = model.fit(model_input, train[target].values, batch_size=batch_size, epochs=epoch, verbose=2, validation_split=15/85)\n",
    "            \n",
    "            # save results of a specific hyperparameter combination\n",
    "            res = pd.DataFrame({key: values[-1] for key, values in history.history.items()}, index=[0])\n",
    "            res['epoch'] = epoch\n",
    "            res['learning rate'] = lr\n",
    "            res['hidden layers'] = str(layers)\n",
    "\n",
    "            # add result to dataframe with all results\n",
    "            results = pd.concat([results, res], ignore_index=True)\n",
    "            results.to_csv('results/DeepFM_hyperparameter.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_crossentropy</th>\n",
       "      <th>auc</th>\n",
       "      <th>val_binary_crossentropy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>epoch</th>\n",
       "      <th>learning rate</th>\n",
       "      <th>hidden layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.519260</td>\n",
       "      <td>0.519240</td>\n",
       "      <td>0.808140</td>\n",
       "      <td>0.594707</td>\n",
       "      <td>0.723408</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.530083</td>\n",
       "      <td>0.530079</td>\n",
       "      <td>0.799480</td>\n",
       "      <td>0.596942</td>\n",
       "      <td>0.723351</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.530657</td>\n",
       "      <td>0.530660</td>\n",
       "      <td>0.799030</td>\n",
       "      <td>0.597083</td>\n",
       "      <td>0.723314</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[400, 400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.531886</td>\n",
       "      <td>0.531890</td>\n",
       "      <td>0.797952</td>\n",
       "      <td>0.595699</td>\n",
       "      <td>0.723273</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.531448</td>\n",
       "      <td>0.531445</td>\n",
       "      <td>0.798568</td>\n",
       "      <td>0.598140</td>\n",
       "      <td>0.723119</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.530541</td>\n",
       "      <td>0.530543</td>\n",
       "      <td>0.799026</td>\n",
       "      <td>0.595682</td>\n",
       "      <td>0.723037</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.524921</td>\n",
       "      <td>0.524887</td>\n",
       "      <td>0.803021</td>\n",
       "      <td>0.594686</td>\n",
       "      <td>0.723035</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.531261</td>\n",
       "      <td>0.531256</td>\n",
       "      <td>0.798682</td>\n",
       "      <td>0.595591</td>\n",
       "      <td>0.723023</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.533755</td>\n",
       "      <td>0.533759</td>\n",
       "      <td>0.796693</td>\n",
       "      <td>0.597328</td>\n",
       "      <td>0.723018</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[400, 400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.532274</td>\n",
       "      <td>0.532275</td>\n",
       "      <td>0.797886</td>\n",
       "      <td>0.596650</td>\n",
       "      <td>0.722985</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[400, 400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.533761</td>\n",
       "      <td>0.533761</td>\n",
       "      <td>0.797152</td>\n",
       "      <td>0.595942</td>\n",
       "      <td>0.722939</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.529991</td>\n",
       "      <td>0.529984</td>\n",
       "      <td>0.799436</td>\n",
       "      <td>0.596285</td>\n",
       "      <td>0.722876</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.533458</td>\n",
       "      <td>0.533452</td>\n",
       "      <td>0.796902</td>\n",
       "      <td>0.596191</td>\n",
       "      <td>0.722852</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.533679</td>\n",
       "      <td>0.533677</td>\n",
       "      <td>0.797245</td>\n",
       "      <td>0.596064</td>\n",
       "      <td>0.722788</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.525545</td>\n",
       "      <td>0.525511</td>\n",
       "      <td>0.802571</td>\n",
       "      <td>0.598304</td>\n",
       "      <td>0.722655</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.521740</td>\n",
       "      <td>0.521711</td>\n",
       "      <td>0.805973</td>\n",
       "      <td>0.595504</td>\n",
       "      <td>0.722532</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[400, 400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.536358</td>\n",
       "      <td>0.536341</td>\n",
       "      <td>0.793833</td>\n",
       "      <td>0.596008</td>\n",
       "      <td>0.722447</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.533713</td>\n",
       "      <td>0.533700</td>\n",
       "      <td>0.795937</td>\n",
       "      <td>0.596410</td>\n",
       "      <td>0.722157</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[400, 400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.536265</td>\n",
       "      <td>0.536247</td>\n",
       "      <td>0.793882</td>\n",
       "      <td>0.596431</td>\n",
       "      <td>0.722075</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.533225</td>\n",
       "      <td>0.533204</td>\n",
       "      <td>0.796271</td>\n",
       "      <td>0.595413</td>\n",
       "      <td>0.721591</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.497020</td>\n",
       "      <td>0.496951</td>\n",
       "      <td>0.827431</td>\n",
       "      <td>0.601790</td>\n",
       "      <td>0.720897</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[400, 400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.512476</td>\n",
       "      <td>0.511658</td>\n",
       "      <td>0.816737</td>\n",
       "      <td>0.600445</td>\n",
       "      <td>0.718815</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[400, 400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.485084</td>\n",
       "      <td>0.485016</td>\n",
       "      <td>0.837009</td>\n",
       "      <td>0.600358</td>\n",
       "      <td>0.718623</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.497265</td>\n",
       "      <td>0.495772</td>\n",
       "      <td>0.829702</td>\n",
       "      <td>0.602918</td>\n",
       "      <td>0.717986</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.507249</td>\n",
       "      <td>0.506366</td>\n",
       "      <td>0.821081</td>\n",
       "      <td>0.600432</td>\n",
       "      <td>0.717605</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.496793</td>\n",
       "      <td>0.496712</td>\n",
       "      <td>0.827985</td>\n",
       "      <td>0.601154</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.503455</td>\n",
       "      <td>0.503374</td>\n",
       "      <td>0.822500</td>\n",
       "      <td>0.601703</td>\n",
       "      <td>0.717019</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.506925</td>\n",
       "      <td>0.506030</td>\n",
       "      <td>0.821273</td>\n",
       "      <td>0.600793</td>\n",
       "      <td>0.716440</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.497110</td>\n",
       "      <td>0.495605</td>\n",
       "      <td>0.829687</td>\n",
       "      <td>0.608365</td>\n",
       "      <td>0.714869</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.491431</td>\n",
       "      <td>0.488849</td>\n",
       "      <td>0.835401</td>\n",
       "      <td>0.607841</td>\n",
       "      <td>0.714613</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.502602</td>\n",
       "      <td>0.501331</td>\n",
       "      <td>0.825609</td>\n",
       "      <td>0.608357</td>\n",
       "      <td>0.714470</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[400, 400, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.507318</td>\n",
       "      <td>0.506432</td>\n",
       "      <td>0.821047</td>\n",
       "      <td>0.602031</td>\n",
       "      <td>0.714194</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.491400</td>\n",
       "      <td>0.488827</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.607785</td>\n",
       "      <td>0.713864</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491096</td>\n",
       "      <td>0.488494</td>\n",
       "      <td>0.835527</td>\n",
       "      <td>0.611368</td>\n",
       "      <td>0.710532</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.496869</td>\n",
       "      <td>0.495391</td>\n",
       "      <td>0.829866</td>\n",
       "      <td>0.609082</td>\n",
       "      <td>0.709873</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[100, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.497553</td>\n",
       "      <td>0.495678</td>\n",
       "      <td>0.830340</td>\n",
       "      <td>0.614921</td>\n",
       "      <td>0.709501</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[400, 400, 400]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  binary_crossentropy       auc  val_binary_crossentropy  \\\n",
       "22  0.519260             0.519240  0.808140                 0.594707   \n",
       "17  0.530083             0.530079  0.799480                 0.596942   \n",
       "35  0.530657             0.530660  0.799030                 0.597083   \n",
       "25  0.531886             0.531890  0.797952                 0.595699   \n",
       "16  0.531448             0.531445  0.798568                 0.598140   \n",
       "26  0.530541             0.530543  0.799026                 0.595682   \n",
       "4   0.524921             0.524887  0.803021                 0.594686   \n",
       "7   0.531261             0.531256  0.798682                 0.595591   \n",
       "33  0.533755             0.533759  0.796693                 0.597328   \n",
       "34  0.532274             0.532275  0.797886                 0.596650   \n",
       "15  0.533761             0.533761  0.797152                 0.595942   \n",
       "8   0.529991             0.529984  0.799436                 0.596285   \n",
       "24  0.533458             0.533452  0.796902                 0.596191   \n",
       "6   0.533679             0.533677  0.797245                 0.596064   \n",
       "13  0.525545             0.525511  0.802571                 0.598304   \n",
       "31  0.521740             0.521711  0.805973                 0.595504   \n",
       "12  0.536358             0.536341  0.793833                 0.596008   \n",
       "30  0.533713             0.533700  0.795937                 0.596410   \n",
       "3   0.536265             0.536247  0.793882                 0.596431   \n",
       "21  0.533225             0.533204  0.796271                 0.595413   \n",
       "32  0.497020             0.496951  0.827431                 0.601790   \n",
       "27  0.512476             0.511658  0.816737                 0.600445   \n",
       "23  0.485084             0.485016  0.837009                 0.600358   \n",
       "19  0.497265             0.495772  0.829702                 0.602918   \n",
       "18  0.507249             0.506366  0.821081                 0.600432   \n",
       "5   0.496793             0.496712  0.827985                 0.601154   \n",
       "14  0.503455             0.503374  0.822500                 0.601703   \n",
       "9   0.506925             0.506030  0.821273                 0.600793   \n",
       "10  0.497110             0.495605  0.829687                 0.608365   \n",
       "20  0.491431             0.488849  0.835401                 0.607841   \n",
       "28  0.502602             0.501331  0.825609                 0.608357   \n",
       "0   0.507318             0.506432  0.821047                 0.602031   \n",
       "11  0.491400             0.488827  0.835052                 0.607785   \n",
       "2   0.491096             0.488494  0.835527                 0.611368   \n",
       "1   0.496869             0.495391  0.829866                 0.609082   \n",
       "29  0.497553             0.495678  0.830340                 0.614921   \n",
       "\n",
       "     val_auc  epoch  learning rate    hidden layers  \n",
       "22  0.723408      5         0.0010       [400, 400]  \n",
       "17  0.723351     10         0.0001  [100, 100, 100]  \n",
       "35  0.723314     10         0.0001  [400, 400, 400]  \n",
       "25  0.723273      5         0.0001       [400, 400]  \n",
       "16  0.723119      5         0.0001  [100, 100, 100]  \n",
       "26  0.723037     10         0.0001       [400, 400]  \n",
       "4   0.723035      5         0.0010       [100, 100]  \n",
       "7   0.723023      5         0.0001       [100, 100]  \n",
       "33  0.723018      3         0.0001  [400, 400, 400]  \n",
       "34  0.722985      5         0.0001  [400, 400, 400]  \n",
       "15  0.722939      3         0.0001  [100, 100, 100]  \n",
       "8   0.722876     10         0.0001       [100, 100]  \n",
       "24  0.722852      3         0.0001       [400, 400]  \n",
       "6   0.722788      3         0.0001       [100, 100]  \n",
       "13  0.722655      5         0.0010  [100, 100, 100]  \n",
       "31  0.722532      5         0.0010  [400, 400, 400]  \n",
       "12  0.722447      3         0.0010  [100, 100, 100]  \n",
       "30  0.722157      3         0.0010  [400, 400, 400]  \n",
       "3   0.722075      3         0.0010       [100, 100]  \n",
       "21  0.721591      3         0.0010       [400, 400]  \n",
       "32  0.720897     10         0.0010  [400, 400, 400]  \n",
       "27  0.718815      3         0.0100  [400, 400, 400]  \n",
       "23  0.718623     10         0.0010       [400, 400]  \n",
       "19  0.717986      5         0.0100       [400, 400]  \n",
       "18  0.717605      3         0.0100       [400, 400]  \n",
       "5   0.717514     10         0.0010       [100, 100]  \n",
       "14  0.717019     10         0.0010  [100, 100, 100]  \n",
       "9   0.716440      3         0.0100  [100, 100, 100]  \n",
       "10  0.714869      5         0.0100  [100, 100, 100]  \n",
       "20  0.714613     10         0.0100       [400, 400]  \n",
       "28  0.714470      5         0.0100  [400, 400, 400]  \n",
       "0   0.714194      3         0.0100       [100, 100]  \n",
       "11  0.713864     10         0.0100  [100, 100, 100]  \n",
       "2   0.710532     10         0.0100       [100, 100]  \n",
       "1   0.709873      5         0.0100       [100, 100]  \n",
       "29  0.709501     10         0.0100  [400, 400, 400]  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for the best performing hyper parameter combination\n",
    "results = pd.read_csv('results/DeepFM_hyperparameter.csv').drop(columns='Unnamed: 0')\n",
    "results.sort_values(by=['val_auc'], ascending=False, inplace=True)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal hyperparameters\n",
    "epoch_opt = 5\n",
    "lr_opt = 0.001\n",
    "layers_opt = [400, 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 697783 samples, validate on 149526 samples, 2726 steps per epoch\n",
      "Epoch 1/5\n",
      "42s - loss:  0.5596 - binary_crossentropy:  0.5596 - auc:  0.7706 - val_binary_crossentropy:  0.5985 - val_auc:  0.7199\n",
      "Epoch 2/5\n",
      "41s - loss:  0.5392 - binary_crossentropy:  0.5392 - auc:  0.7912 - val_binary_crossentropy:  0.5978 - val_auc:  0.7211\n",
      "Epoch 3/5\n",
      "43s - loss:  0.5332 - binary_crossentropy:  0.5332 - auc:  0.7963 - val_binary_crossentropy:  0.5954 - val_auc:  0.7216\n",
      "Epoch 4/5\n",
      "44s - loss:  0.5249 - binary_crossentropy:  0.5249 - auc:  0.8033 - val_binary_crossentropy:  0.5950 - val_auc:  0.7227\n",
      "Epoch 5/5\n",
      "51s - loss:  0.5193 - binary_crossentropy:  0.5192 - auc:  0.8081 - val_binary_crossentropy:  0.5947 - val_auc:  0.7234\n"
     ]
    }
   ],
   "source": [
    "# train the model with optimal hyperparameters\n",
    "model_opt = DeepFM(linear_feature_columns, dnn_feature_columns, use_fm=True, \n",
    "                        dnn_hidden_units=layers_opt,\n",
    "                        dnn_dropout=dropout_rate,\n",
    "                        task='binary',\n",
    "                        dnn_activation=activation)\n",
    "\n",
    "model_opt.compile(torch.optim.Adam(model_opt.parameters(), lr=lr_opt), 'binary_crossentropy', metrics=['binary_crossentropy', 'auc'])\n",
    "history_opt = model_opt.fit(model_input, train[target].values, batch_size=batch_size, epochs=epoch_opt, verbose=2, validation_split=15/85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict rating for each user item combination and append it to the test dataframe\n",
    "predictions = model_opt.predict(model_input_test)\n",
    "test['Prediction'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list with all users to loop over\n",
    "users = test.User.unique()\n",
    "\n",
    "# Initialize DataFrames to store results\n",
    "awhrs = pd.DataFrame()\n",
    "asats = pd.DataFrame()\n",
    "asats_2 = pd.DataFrame()\n",
    "\n",
    "# Lists to store Kendall distance sums\n",
    "kendal_sum = []\n",
    "kendal_sum_2 = []\n",
    "\n",
    "# Loop over different values of k\n",
    "for k in [1, 5, 10, 20, 50]:\n",
    "    # Initialize lists to store @k metrics\n",
    "    whrs = []\n",
    "    sat_us = []\n",
    "    sat_us_2 = []\n",
    "    recommendations_allu = []\n",
    "    \n",
    "    # Loop over each user\n",
    "    for user in users:\n",
    "        # Initialize metrics for a specific user\n",
    "        whr = 0\n",
    "        sat = 0\n",
    "        sat_2 = 0\n",
    "\n",
    "        # Filter predictions for the current user\n",
    "        predictions_user = test[test['User']==user]\n",
    "        # Get top-k recommendations for the user\n",
    "        recommendations = predictions_user.sort_values('Prediction', ascending=False).head(k)\n",
    "\n",
    "        # Calculate weighted hit rate and user satisfaction\n",
    "        for rec in recommendations['Rating']:\n",
    "            if rec == 1:\n",
    "                whr -= 5\n",
    "            elif rec == 2:\n",
    "                whr -= 2\n",
    "            elif rec == 3:\n",
    "                whr += 2\n",
    "            elif rec == 4:\n",
    "                whr += 6\n",
    "                sat = 1\n",
    "            elif rec == 5:\n",
    "                whr += 12\n",
    "                sat = 1\n",
    "                sat_2 = 1\n",
    "                \n",
    "        whr = whr / k\n",
    "        whrs.append(whr)\n",
    "        sat_us.append(sat)\n",
    "        sat_us_2.append(sat_2)\n",
    "        \n",
    "        # Store recommendations for the user\n",
    "        recommendations_allu.append(list(recommendations['Movie'])) \n",
    "\n",
    "        # Calculate Kendall distance with penalty\n",
    "        # only once as it uses the whole sequence of predictions and is therefore independend of k\n",
    "        if k == 1:\n",
    "            kendal_u = kendall_distance_with_penalty(predictions_user[~predictions_user['Rating'].isna()], predictions_user[~predictions_user['Rating'].isna()], 'Movie', 'Movie', 'Rating_x', 'Prediction_x', p = 0.05)\n",
    "            kendal_u_2 = kendall_distance_with_penalty(predictions_user[~predictions_user['Rating'].isna()], predictions_user[~predictions_user['Rating'].isna()], 'Movie', 'Movie', 'Rating_x', 'Prediction_x', p = 0.2)\n",
    "\n",
    "            kendal_sum.append(kendal_u)\n",
    "            kendal_sum_2.append(kendal_u_2)\n",
    "\n",
    "    # Calculate average weighted hit rate for current k\n",
    "    average_whr = pd.DataFrame({'Average Weigthed Hit Rate': np.mean(whrs), 'k': k}, index=[0])\n",
    "    \n",
    "    # Calculate average user satisfaction for current k (with satisfaction weight 1)\n",
    "    average_sat = pd.DataFrame({'Average User Satisfaction':np.mean(sat_us), 'k': k}, index=[0])\n",
    "    \n",
    "    # Calculate average user satisfaction for current k (with satisfaction weight 2)\n",
    "    average_sat_2 = pd.DataFrame({'Average User Satisfaction':np.mean(sat_us_2), 'k': k}, index=[0])\n",
    "    \n",
    "    # Store recommendation distribution for current k\n",
    "    recommendations_k = pd.DataFrame({'Element': pd.Series(recommendations_allu).index, 'Occurrence Count': pd.Series(recommendations_allu).values})\n",
    "    recommendations_k.to_csv(f'results/Recommendation_distribution@{k}.csv')\n",
    "\n",
    "    # Concatenate results for current k to the overall DataFrames\n",
    "    awhrs = pd.concat([awhrs, average_whr], ignore_index=True)\n",
    "    asats = pd.concat([asats, average_sat], ignore_index=True)\n",
    "    asats_2 = pd.concat([asats_2, average_sat_2], ignore_index=True)\n",
    "\n",
    "# Calculate average Kendall distance\n",
    "kendal = pd.DataFrame({'Kendall Distance':np.mean(kendal_sum), 'p': 0.05}, index=[0])\n",
    "kendal_2 = pd.DataFrame({'Kendall Distance':np.mean(kendal_sum_2), 'p': 0.2}, index=[0])\n",
    "# Concatenate results for different values of p\n",
    "kendal = pd.concat([kendal, kendal_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "awhrs.to_csv('results/DeepFM_awhrs.csv')\n",
    "asats.to_csv('results/DeepFM_asats.csv')\n",
    "asats_2.to_csv('results/DeepFM_asats2.csv')\n",
    "kendal.to_csv('results/DeepFM_Kendall.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
