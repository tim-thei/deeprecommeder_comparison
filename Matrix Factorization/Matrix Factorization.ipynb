{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import later used packages\n",
    "from surprise import SVD\n",
    "import surprise\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# custom functions see .py files\n",
    "from Rec_split import rec_split\n",
    "from Kendall_distance import kendall_distance_with_penalty\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preporcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "df = pd.read_csv('data/ml_1M_full.csv')\n",
    "\n",
    "#drop not needed columns\n",
    "df = df.drop(columns=['Gender', 'Age', 'Occupation', 'Genre'])\n",
    "#split data\n",
    "train_df, val_df, test = rec_split(df, 'User', 'Timestamp', train_share=0.7, val_share=0.15)\n",
    "\n",
    "#read data to surprise\n",
    "reader = surprise.Reader(rating_scale=(1, 5))\n",
    "train = surprise.Dataset.load_from_df(train_df[['User', 'Movie', 'Rating']], reader)\n",
    "val = surprise.Dataset.load_from_df(val_df[['User', 'Movie', 'Rating']], reader)\n",
    "\n",
    "train = train.build_full_trainset()\n",
    "val = val.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "epochs = [50, 100, 250, 500, 1000]\n",
    "learning_rate = [0.0001, 0.001, 0.1, 1]\n",
    "emb_dim = [16, 32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9577\n",
      "RMSE: 0.9584\n",
      "RMSE: 0.9596\n",
      "RMSE: 0.9621\n",
      "RMSE: 0.9682\n",
      "RMSE: 0.9073\n",
      "RMSE: 0.9072\n",
      "RMSE: 0.9035\n",
      "RMSE: 0.9040\n",
      "RMSE: 0.9062\n",
      "RMSE: 0.9748\n",
      "RMSE: 1.0131\n",
      "RMSE: 1.0560\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 0.9344\n",
      "RMSE: 0.9350\n",
      "RMSE: 0.9364\n",
      "RMSE: 0.9393\n",
      "RMSE: 0.9447\n",
      "RMSE: 0.8858\n",
      "RMSE: 0.8841\n",
      "RMSE: 0.8865\n",
      "RMSE: 0.8929\n",
      "RMSE: 0.9001\n",
      "RMSE: 0.9741\n",
      "RMSE: 1.0168\n",
      "RMSE: 1.0570\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 0.9181\n",
      "RMSE: 0.9187\n",
      "RMSE: 0.9199\n",
      "RMSE: 0.9204\n",
      "RMSE: 0.9240\n",
      "RMSE: 0.8824\n",
      "RMSE: 0.9000\n",
      "RMSE: 0.9186\n",
      "RMSE: 0.9235\n",
      "RMSE: 0.9119\n",
      "RMSE: 0.9751\n",
      "RMSE: 1.0157\n",
      "RMSE: 1.0569\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 0.9099\n",
      "RMSE: 0.9071\n",
      "RMSE: 0.9046\n",
      "RMSE: 0.9048\n",
      "RMSE: 0.9067\n",
      "RMSE: 0.8964\n",
      "RMSE: 0.9256\n",
      "RMSE: 0.9482\n",
      "RMSE: 0.9380\n",
      "RMSE: 0.9104\n",
      "RMSE: 0.9738\n",
      "RMSE: 1.0173\n",
      "RMSE: 1.0564\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 0.8887\n",
      "RMSE: 0.8859\n",
      "RMSE: 0.8902\n",
      "RMSE: 0.8937\n",
      "RMSE: 0.9001\n",
      "RMSE: 0.9047\n",
      "RMSE: 0.9415\n",
      "RMSE: 0.9615\n",
      "RMSE: 0.9455\n",
      "RMSE: 0.9049\n",
      "RMSE: 0.9746\n",
      "RMSE: 1.0148\n",
      "RMSE: 1.0561\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n",
      "RMSE: 1.8814\n"
     ]
    }
   ],
   "source": [
    "# generate empty dataframe to save results\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for epoch in epochs:\n",
    "    for lr in learning_rate:\n",
    "        for K in emb_dim:\n",
    "            # train the model for each hyperparameter combination\n",
    "            mf = SVD(n_factors=K,\n",
    "                        n_epochs = epoch,\n",
    "                        lr_all = lr)\n",
    "            mf.fit(train)\n",
    "            # evaluate hyperparameter on validation set\n",
    "            preds = mf.test(val.build_testset())\n",
    "            val_rmse = surprise.accuracy.rmse(preds)\n",
    "\n",
    "            # save results of a specific hyperparameter combination\n",
    "            res = pd.DataFrame({'val RMSE': val_rmse, 'embedding dimention': K, 'learning rate': lr, 'epochs': epoch}, index=[0])\n",
    "            # add result to dataframe with all results\n",
    "            results = pd.concat([results, res], ignore_index=True)\n",
    "            results.to_csv('results/MF_hyperparameter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val RMSE</th>\n",
       "      <th>embedding dimention</th>\n",
       "      <th>learning rate</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.882416</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.884062</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.885840</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.885891</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.886497</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.881353</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.881353</td>\n",
       "      <td>256</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.881353</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.881353</td>\n",
       "      <td>256</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.881353</td>\n",
       "      <td>256</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    val RMSE  embedding dimention  learning rate  epochs\n",
       "45  0.882416                   16         0.0010     250\n",
       "26  0.884062                   32         0.0010     100\n",
       "25  0.885840                   16         0.0010     100\n",
       "81  0.885891                   32         0.0001    1000\n",
       "27  0.886497                   64         0.0010     100\n",
       "..       ...                  ...            ...     ...\n",
       "15  1.881353                   16         1.0000      50\n",
       "39  1.881353                  256         1.0000     100\n",
       "73  1.881353                  128         0.1000     500\n",
       "59  1.881353                  256         1.0000     250\n",
       "99  1.881353                  256         1.0000    1000\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for the best performing hyper parameter combination\n",
    "results = pd.read_csv('results/MF_hyperparameter.csv').drop(columns='Unnamed: 0')\n",
    "results.sort_values('val RMSE', inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal hyperparameter\n",
    "epochs_opt = 250\n",
    "lr_opt  = 0.001\n",
    "emb_dim_opt = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x237ff434050>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model with optimal hyperparameters\n",
    "mf_opt = SVD(n_factors=emb_dim_opt,\n",
    "             n_epochs = epochs_opt,\n",
    "             lr_all = lr_opt)\n",
    "\n",
    "mf_opt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build prediction dataset\n",
    "predset = train.build_anti_testset()\n",
    "\n",
    "# generate predictions\n",
    "predictions = mf_opt.test(predset)\n",
    "\n",
    "# convert predictions to a pandas dataframe\n",
    "predictions = [(pred.uid, pred.iid, pred.r_ui, pred.est, pred.details['was_impossible']) for pred in predictions]\n",
    "predictions = pd.DataFrame(predictions, columns=['User', 'Movie', 'r_ui', 'Prediction', 'was_impossible']).drop(columns=['r_ui', 'was_impossible'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = test[test['User']==1]\n",
    "\n",
    "b = a[a['Movie']==2687]['Rating']\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting unique users from the training data\n",
    "users = train_df.User.unique()\n",
    "\n",
    "# Initializing DataFrames to store results\n",
    "awhrs = pd.DataFrame()\n",
    "asats = pd.DataFrame()\n",
    "asats_2 = pd.DataFrame()\n",
    "\n",
    "# List to store Kendall Distance sums for each user\n",
    "kendal_sum = []  \n",
    "kendal_sum_2 = []\n",
    "\n",
    "# Looping through different values of k\n",
    "for k in [1, 5, 10, 20, 50]:\n",
    "    whrs = []  # List to store Weighted Hit Rates for each user\n",
    "    sat_us = []  # List to store User Satisfaction values for each user\n",
    "    sat_us_2 = []  # List to store User Satisfaction values (with different threshold) for each user\n",
    "    recommendations_allu = []  # List to store recommendations for each user\n",
    "    \n",
    "    # Looping through each user\n",
    "    for user in users:\n",
    "        whr = 0  # Initializing Weighted Hit Rate for the user\n",
    "        sat = 0  # Initializing User Satisfaction for the user\n",
    "        sat_2 = 0  # Initializing User Satisfaction (with different threshold) for the user\n",
    "        \n",
    "        ratings = test[test['User']==user]  # Extracting ratings for the current user\n",
    "        \n",
    "        predictions_user = predictions[predictions['User']==user]  # Extracting predictions for the current user\n",
    "        recommendations = predictions_user.sort_values('Prediction', ascending=False).head(k)  # Selecting top k recommendations\n",
    "        \n",
    "        # Calculating Weighted Hit Rate and User Satisfaction for the current user\n",
    "        for rec in recommendations['Movie'].values:\n",
    "            if len(ratings[ratings['Movie']==rec]['Rating']) == 1:\n",
    "                rat = ratings[ratings['Movie']==rec]['Rating'].values[0]\n",
    "                if rat == 1:\n",
    "                    whr -= 5\n",
    "                elif rat == 2:\n",
    "                    whr -= 2\n",
    "                elif rat == 3:\n",
    "                    whr += 2\n",
    "                elif rat == 4:\n",
    "                    whr += 6\n",
    "                    sat = 1\n",
    "                elif rat == 5:\n",
    "                    whr += 12\n",
    "                    sat = 1\n",
    "                    sat_2 = 1\n",
    "        \n",
    "        whr = whr / k  # Calculating Weighted Hit Rate per recommendation\n",
    "        whrs.append(whr)\n",
    "        sat_us.append(sat)\n",
    "        sat_us_2.append(sat_2)\n",
    "        recommendations_allu.append(list(recommendations['Movie']))  # Storing recommendations for the current user\n",
    "        \n",
    "        # Calculating Kendall Distance with panalty\n",
    "        # only once as it uses the whole sequence of predictions and is therefore independend of k\n",
    "        if k == 1:\n",
    "            kendal_u = kendall_distance_with_penalty(predictions_user, ratings, 'Movie', 'Movie', 'Prediction', 'Rating', p=0.05)\n",
    "            kendal_u_2 = kendall_distance_with_penalty(predictions_user, ratings, 'Movie', 'Movie', 'Prediction', 'Rating', p=0.2)\n",
    "            \n",
    "            kendal_sum.append(kendal_u)\n",
    "            kendal_sum_2.append(kendal_u_2)\n",
    "    \n",
    "    # Calculating average Weighted Hit Rate for current k\n",
    "    average_whr = pd.DataFrame({'Average Weigthed Hit Rate': np.mean(whrs), 'k': k}, index=[0])\n",
    "    # Calculating average User Satisfaction for current k\n",
    "    average_sat = pd.DataFrame({'Average User Satisfaction': np.mean(sat_us), 'k': k}, index=[0])\n",
    "    # Calculating average User Satisfaction (with different threshold) for current k\n",
    "    average_sat_2 = pd.DataFrame({'Average User Satisfaction': np.mean(sat_us_2), 'k': k}, index=[0])\n",
    "    \n",
    "    # Saving recommendation distribution for current k to a CSV file\n",
    "    recommendations_k = pd.DataFrame({'Element': pd.Series(recommendations_allu).index,\n",
    "                                      'Occurrence Count': pd.Series(recommendations_allu).values})\n",
    "    recommendations_k.to_csv(f'results/Recommendation_distribution@{k}.csv')\n",
    "    \n",
    "    # Appending results to respective DataFrames\n",
    "    awhrs = pd.concat([awhrs, average_whr], ignore_index=True)\n",
    "    asats = pd.concat([asats, average_sat], ignore_index=True)\n",
    "    asats_2 = pd.concat([asats_2, average_sat_2], ignore_index=True)\n",
    "\n",
    "# Calculating average Kendall Distance\n",
    "kendal = pd.DataFrame({'Kendall Distance': np.mean(kendal_sum), 'p': 0.05}, index=[0])\n",
    "kendal_2 = pd.DataFrame({'Kendall Distance': np.mean(kendal_sum_2), 'p': 0.2}, index=[0])\n",
    "# Concatenating both Kendall Distance DataFrames\n",
    "kendal = pd.concat([kendal, kendal_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "awhrs.to_csv('results/MF_awhrs.csv')\n",
    "asats.to_csv('results/MF_asats.csv')\n",
    "asats_2.to_csv('results/MF_asats2.csv')\n",
    "kendal.to_csv('results/MF_Kendall.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
