{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import later used packages\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "#import custom made functions, see .py files\n",
    "from Rec_split import rec_split\n",
    "from Kendall_distance import kendall_distance_with_penalty\n",
    "\n",
    "np.random.seed(123)\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data =pd.read_csv('data/ml_1M_full.csv')\n",
    "train, val , test = rec_split(data, 'User', 'Timestamp', train_share=0.7, val_share=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dataset for prediction generation\n",
    "movie_columns = ['Movie', 'Genre', 'Release_Year']\n",
    "user_columns = ['User', 'Gender', 'Age', 'Occupation']\n",
    "\n",
    "movie_df = train[movie_columns].drop_duplicates()\n",
    "user_df = train[user_columns].drop_duplicates()\n",
    "\n",
    "# Create combinations of rows from both DataFrames\n",
    "combined_rows = [list(row1) + list(row2) for row1, row2 in product(movie_df.values, user_df.values)]\n",
    "\n",
    "# Create a new DataFrame with columns from both DataFrames\n",
    "columns = list(movie_df.columns) + list(user_df.columns)\n",
    "prediction_df = pd.DataFrame(combined_rows, columns=columns)\n",
    "\n",
    "#remove data already in train\n",
    "merged_df = pd.merge(prediction_df, train, on=['User', 'Movie'], how='outer', indicator=True)\n",
    "merged_df = merged_df[merged_df['_merge']=='left_only'].drop(columns=['_merge', 'Rating', 'Gender_y', 'Age_y', 'Occupation_y', 'Genre_y', 'Release_Year_y']).rename(columns=lambda x: x.replace('_x', ''))\n",
    "\n",
    "#remove data already in val\n",
    "merged_df = pd.merge(prediction_df, val, on=['User', 'Movie'], how='outer', indicator=True)\n",
    "prediction_df = merged_df[merged_df['_merge']=='left_only'].drop(columns=['_merge', 'Rating', 'Gender_y', 'Age_y', 'Occupation_y', 'Genre_y', 'Release_Year_y']).rename(columns=lambda x: x.replace('_x', ''))\n",
    "\n",
    "#remove movies exclusivly in test\n",
    "prediction_df = pd.merge(prediction_df, test, on=['User', 'Movie'], how='outer', indicator=True)\n",
    "test = prediction_df[prediction_df['_merge']!='right_only'].drop(columns=['_merge', 'Gender_y', 'Age_y', 'Occupation_y', 'Genre_y', 'Release_Year_y']).rename(columns=lambda x: x.replace('_x', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 'Predictions'\n",
    "test['Prediction'] = np.random.randint(1, 6, size=len(test))\n",
    "test['Prediction_2'] = np.random.randint(1, 6, size=len(test))\n",
    "test['Prediction_3'] = np.random.randint(1, 6, size=len(test))\n",
    "test['Prediction_4'] = np.random.randint(1, 6, size=len(test))\n",
    "test['Prediction_5'] = np.random.randint(1, 6, size=len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate metrics for random recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = test.User.unique()\n",
    "\n",
    "awhrs = pd.DataFrame()\n",
    "asats = pd.DataFrame()\n",
    "asats_2 = pd.DataFrame()\n",
    "\n",
    "for k in [1, 5, 10, 20, 50]:\n",
    "    whrs = []\n",
    "    sat_us = []\n",
    "    sat_us_2 = []\n",
    "    recommendations_allu = []\n",
    "    \n",
    "    for user in users:\n",
    "        whr = 0\n",
    "        sat = 0\n",
    "        sat_2 = 0\n",
    "        kendal_u = 0\n",
    "        kendal_u_2 = 0\n",
    "        \n",
    "        for pred in ['Prediction', 'Prediction_2', 'Prediction_3', 'Prediction_4', 'Prediction_5']:\n",
    "            predictions_user = test[test['User']==user]\n",
    "            recommendations = predictions_user.sort_values(pred, ascending=False).head(k)\n",
    "            \n",
    "            # Calculate weighted hit rate and user satisfaction\n",
    "            for rec in recommendations['Rating']:\n",
    "                if rec == 1:\n",
    "                    whr -= 5\n",
    "                elif rec == 2:\n",
    "                    whr -= 2\n",
    "                elif rec == 3:\n",
    "                    whr += 2\n",
    "                elif rec == 4:\n",
    "                    whr += 6\n",
    "                    sat = 1\n",
    "                elif rec == 5:\n",
    "                    whr += 12\n",
    "                    sat = 1\n",
    "                    sat_2 = 1\n",
    "        \n",
    "        whr = whr / 5    \n",
    "        whr = whr / k\n",
    "        whrs.append(whr)\n",
    "\n",
    "        sat = sat / 5\n",
    "        sat_us.append(sat)\n",
    "\n",
    "        sat_2 = sat_2 / 5\n",
    "        sat_us_2.append(sat_2)\n",
    "\n",
    "        # Store recommendations for the user\n",
    "        recommendations_allu.append(list(recommendations['Movie']))   \n",
    "\n",
    "    average_whr = pd.DataFrame({'Average Weigthed Hit Rate': np.mean(whrs), 'k': k}, index=[0])\n",
    "    average_sat = pd.DataFrame({'Average User Satisfaction':np.mean(sat_us), 'k': k}, index=[0])\n",
    "    average_sat_2 = pd.DataFrame({'Average User Satisfaction':np.mean(sat_us_2), 'k': k}, index=[0])\n",
    "\n",
    "    # Store recommendation distribution for current k\n",
    "    recommendations_k = pd.DataFrame({'Element': pd.Series(recommendations_allu).index, 'Occurrence Count': pd.Series(recommendations_allu).values})\n",
    "    recommendations_k.to_csv(f'results/Recommendation_distribution@{k}.csv')\n",
    "\n",
    "    awhrs = pd.concat([awhrs, average_whr], ignore_index=True)\n",
    "    asats = pd.concat([asats, average_sat], ignore_index=True)\n",
    "    asats_2 = pd.concat([asats_2, average_sat_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "awhrs.to_csv('results/random_awhrs.csv')\n",
    "asats.to_csv('results/random_asats.csv')\n",
    "asats_2.to_csv('results/random_asats2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute Kendall distance with p\n",
    "kendal_pred = []\n",
    "kendal_pred_2 = []\n",
    "\n",
    "for pred in ['Prediction', 'Prediction_2', 'Prediction_3', 'Prediction_4', 'Prediction_5']:\n",
    "    kendal_list = []\n",
    "    kendal_list_2 = []\n",
    "\n",
    "    for user in test.User.unique():\n",
    "        predictions_user = test[test['User']==user]\n",
    "\n",
    "        kendal_u = kendall_distance_with_penalty(predictions_user[~predictions_user['Rating'].isna()], predictions_user[~predictions_user['Rating'].isna()], 'Movie', 'Movie', 'Rating_x', f'{pred}_x', p = 0.05)\n",
    "        kendal_u_2 = kendall_distance_with_penalty(predictions_user[~predictions_user['Rating'].isna()], predictions_user[~predictions_user['Rating'].isna()], 'Movie', 'Movie', 'Rating_x', f'{pred}_x', p = 0.2)\n",
    "\n",
    "        kendal_list.append(kendal_u)\n",
    "        kendal_list_2.append(kendal_u_2)\n",
    "\n",
    "    kendal_avr = np.mean(kendal_list)\n",
    "    kendal_avr_2 = np.mean(kendal_list_2)\n",
    "\n",
    "    kendal_pred.append(kendal_avr)\n",
    "    kendal_pred_2.append(kendal_avr_2)\n",
    "\n",
    "# Calculate average Kendall distance\n",
    "kendal = pd.DataFrame({'Kendall Distance':np.mean(kendal_pred), 'p': 0.05}, index=[0])\n",
    "kendal_2 = pd.DataFrame({'Kendall Distance':np.mean(kendal_pred_2), 'p': 0.2}, index=[0])\n",
    "# Concatenate results for different values of p\n",
    "kendal = pd.concat([kendal, kendal_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save Kendall distances to csv\n",
    "kendal.to_csv('results/random_Kendall.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
